<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  <meta name="google-site-verification" content="z98GT4PZdRgrcES2hf9DTxMShekuK_k-48TNAutBYZg" />
  
  
    <meta name="msvalidate.01" content="8C31B0044947BFFD6869DD1B5E5E8268" />
  
  
  <meta name="baidu-site-verification" content="code-fDSTdt2hx7" />
  
  
  <title>深度学习推荐系统-笔记05：Embedding技术 | Not late</title>
  <meta name="description" content="1. Embedding是什么 Embedding 就是用一个数值向量“表示”一个对象（Object）的方法  解读1：左边例子，从 king 到 queen 的向量和从 man 到 woman 的向量，无论从方向还是尺度来说它们都非常接近。 解读2：右边例子也很典型，从 walking 到 walked 和从 swimming 到 swam 的向量基本一致，这说明词向量揭示了词之间的时态关系">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习推荐系统-笔记05：Embedding技术">
<meta property="og:url" content="https://www.notlate.net/posts/ba149af9.html">
<meta property="og:site_name" content="Not late yet">
<meta property="og:description" content="1. Embedding是什么 Embedding 就是用一个数值向量“表示”一个对象（Object）的方法  解读1：左边例子，从 king 到 queen 的向量和从 man 到 woman 的向量，无论从方向还是尺度来说它们都非常接近。 解读2：右边例子也很典型，从 walking 到 walked 和从 swimming 到 swam 的向量基本一致，这说明词向量揭示了词之间的时态关系">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221242798.png">
<meta property="og:image" content="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221254567.png">
<meta property="og:image" content="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221303479.png">
<meta property="og:image" content="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221312355.png">
<meta property="og:image" content="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221321966.png">
<meta property="og:image" content="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221333959.png">
<meta property="og:image" content="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221342914.png">
<meta property="og:image" content="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221348626.png">
<meta property="og:image" content="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221355654.png">
<meta property="og:image" content="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221404937.png">
<meta property="og:image" content="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221412660.png">
<meta property="article:published_time" content="2021-01-05T13:02:30.000Z">
<meta property="article:modified_time" content="2021-03-18T15:04:38.506Z">
<meta property="article:author" content="ACDance">
<meta property="article:tag" content="Embedding">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221242798.png">
  <!-- Canonical links -->
  <link rel="canonical" href="https://www.notlate.net/posts/ba149af9.html">
  
    <link rel="alternate" href="/atom.xml" title="Not late yet" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.css" rel="stylesheet">
  
  
  
    <link href="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.3.5/dist/jquery.fancybox.min.css" rel="stylesheet">
  
  
<meta name="generator" content="Hexo 5.3.0"></head>


<body class="main-center theme-blue" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="" target="_blank">
          <img class="img-circle img-rotate" src="/images/logo.png" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">ACDance</h2>
<!--         <h3 id="title" class="hidden-xs hidden-sm hidden-md">一无所知，或是没被理解；&lt;br/&gt;一事无成，或是没被重视。</h3> -->
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">
            一无所知，或是没被理解；<br/>一事无成，或是没被重视。
        </h3>
<!--         <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> </small> -->
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="检索..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav menu-highlight">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/NotLateYet" target="_blank" title="Github" ><i class="icon icon-github"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" ><i class="icon icon-rss"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>欢迎交流与分享经验!</p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">分类</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/">分布式</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">深度学习推荐系统</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/">计算广告</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a><span class="category-list-count">2</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/ADX/" style="font-size: 13px;">ADX</a> <a href="/tags/DSP/" style="font-size: 13px;">DSP</a> <a href="/tags/Embedding/" style="font-size: 13px;">Embedding</a> <a href="/tags/GNN/" style="font-size: 13px;">GNN</a> <a href="/tags/MMoE/" style="font-size: 13px;">MMoE</a> <a href="/tags/SSP/" style="font-size: 13px;">SSP</a> <a href="/tags/mongodb/" style="font-size: 13.5px;">mongodb</a> <a href="/tags/redis/" style="font-size: 13.5px;">redis</a> <a href="/tags/%E4%B8%9A%E7%95%8C%E4%B8%BB%E6%B5%81/" style="font-size: 13px;">业界主流</a> <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" style="font-size: 13.25px;">人工智能</a> <a href="/tags/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/" style="font-size: 13px;">传统算法</a> <a href="/tags/%E4%BF%A1%E6%81%AF%E6%B5%81/" style="font-size: 13px;">信息流</a> <a href="/tags/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/" style="font-size: 13px;">协同过滤</a> <a href="/tags/%E5%8E%9F%E7%94%9F%E5%B9%BF%E5%91%8A/" style="font-size: 13px;">原生广告</a> <a href="/tags/%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/" style="font-size: 13.25px;">发展趋势</a> <a href="/tags/%E5%8F%97%E4%BC%97%E5%AE%9A%E5%90%91/" style="font-size: 13px;">受众定向</a> <a href="/tags/%E5%90%88%E7%BA%A6%E5%B9%BF%E5%91%8A/" style="font-size: 13px;">合约广告</a> <a href="/tags/%E5%9C%A8%E7%BA%BF%E5%B9%BF%E5%91%8A/" style="font-size: 13.25px;">在线广告</a> <a href="/tags/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/" style="font-size: 13px;">工程实践</a> <a href="/tags/%E5%B9%BF%E5%91%8A%E5%9F%BA%E7%A1%80/" style="font-size: 13px;">广告基础</a> <a href="/tags/%E5%B9%BF%E5%91%8A%E6%8A%95%E6%94%BE/" style="font-size: 13px;">广告投放</a> <a href="/tags/%E5%B9%BF%E5%91%8A%E7%BD%91%E7%BB%9C/" style="font-size: 13px;">广告网络</a> <a href="/tags/%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%88%A9%E7%94%A8/" style="font-size: 13px;">探索与利用</a> <a href="/tags/%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B/" style="font-size: 13px;">推荐模型</a> <a href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" style="font-size: 13.75px;">推荐系统</a> <a href="/tags/%E6%90%9C%E7%B4%A2%E5%B9%BF%E5%91%8A/" style="font-size: 13px;">搜索广告</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E4%BA%A4%E6%98%93/" style="font-size: 13px;">数据交易</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%8A%A0%E5%B7%A5/" style="font-size: 13px;">数据加工</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/" style="font-size: 13px;">数据处理</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 14px;">数据库</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 13px;">机器学习</a> <a href="/tags/%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/" style="font-size: 13px;">核心技术</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/" style="font-size: 13px;">模型评估</a> <a href="/tags/%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6/" style="font-size: 13px;">测试框架</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 13.25px;">深度学习</a> <a href="/tags/%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B/" style="font-size: 13px;">点击率预测</a> <a href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" style="font-size: 13px;">特征工程</a> <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" style="font-size: 13px;">知识图谱</a> <a href="/tags/%E7%A8%8B%E5%BA%8F%E5%8C%96%E4%BA%A4%E6%98%93/" style="font-size: 13px;">程序化交易</a> <a href="/tags/%E7%AB%9E%E4%BB%B7%E5%B9%BF%E5%91%8A/" style="font-size: 13px;">竞价广告</a> <a href="/tags/%E7%BA%BF%E4%B8%8A%E6%9C%8D%E5%8A%A1/" style="font-size: 13px;">线上服务</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/" style="font-size: 13px;">计算广告</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">推荐阅读</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled ">
        
          <li>
<!--              -->
<!--             <div class="item-thumb"> -->
<!--               <a href="/posts/d837735f.html" class="thumb">
    
    
        <span class="thumb-image thumb-none"></span>
    
</a>
 -->
<!--             </div> -->
<!--              -->
            <div class="item-inner">
<!--               <p class="item-category"> -->
<!--                 <a class="category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a> -->
<!--               </p> -->
              <p class="item-title">
                <a href="/posts/d837735f.html" class="title">机器之心-2020年AI进展及2021年趋势关注重点笔记</a>
              </p>
              <p class="item-date">
                <time datetime="2021-02-26T12:22:15.000Z" itemprop="datePublished">2021-02-26</time>
              </p>
            </div>
          </li>
          
          <li>
<!--              -->
<!--             <div class="item-thumb"> -->
<!--               <a href="/posts/6cc588ae.html" class="thumb">
    
    
        <span class="thumb-image thumb-none"></span>
    
</a>
 -->
<!--             </div> -->
<!--              -->
            <div class="item-inner">
<!--               <p class="item-category"> -->
<!--                 <a class="category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a> -->
<!--               </p> -->
              <p class="item-title">
                <a href="/posts/6cc588ae.html" class="title">智源研究院-2020年AI进展及2021年趋势关注重点笔记</a>
              </p>
              <p class="item-date">
                <time datetime="2021-02-24T13:36:22.000Z" itemprop="datePublished">2021-02-24</time>
              </p>
            </div>
          </li>
          
          <li>
<!--              -->
<!--             <div class="item-thumb"> -->
<!--               <a href="/posts/a08c2ad5.html" class="thumb">
    
    
        <span class="thumb-image thumb-none"></span>
    
</a>
 -->
<!--             </div> -->
<!--              -->
            <div class="item-inner">
<!--               <p class="item-category"> -->
<!--                 <a class="category-link" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> -->
<!--               </p> -->
              <p class="item-title">
                <a href="/posts/a08c2ad5.html" class="title">GNN笔记01-基础原理与应用</a>
              </p>
              <p class="item-date">
                <time datetime="2021-02-04T06:30:40.000Z" itemprop="datePublished">2021-02-04</time>
              </p>
            </div>
          </li>
          
          <li>
<!--              -->
<!--             <div class="item-thumb"> -->
<!--               <a href="/posts/2c4e9dc8.html" class="thumb">
    
    
        <span class="thumb-image thumb-none"></span>
    
</a>
 -->
<!--             </div> -->
<!--              -->
            <div class="item-inner">
<!--               <p class="item-category"> -->
<!--                 <a class="category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">深度学习推荐系统</a> -->
<!--               </p> -->
              <p class="item-title">
                <a href="/posts/2c4e9dc8.html" class="title">深度学习推荐系统-笔记13：探究业界主流的推荐系统解决方案</a>
              </p>
              <p class="item-date">
                <time datetime="2021-01-05T15:24:40.000Z" itemprop="datePublished">2021-01-05</time>
              </p>
            </div>
          </li>
          
          <li>
<!--              -->
<!--             <div class="item-thumb"> -->
<!--               <a href="/posts/9f710c67.html" class="thumb">
    
    
        <span class="thumb-image thumb-none"></span>
    
</a>
 -->
<!--             </div> -->
<!--              -->
            <div class="item-inner">
<!--               <p class="item-category"> -->
<!--                 <a class="category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">深度学习推荐系统</a> -->
<!--               </p> -->
              <p class="item-title">
                <a href="/posts/9f710c67.html" class="title">深度学习推荐系统-笔记12：模型评估</a>
              </p>
              <p class="item-date">
                <time datetime="2021-01-05T14:28:20.000Z" itemprop="datePublished">2021-01-05</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
      
  <div class="widget">
    <h3 class="widget-title">归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">三月 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">二月 2021</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">一月 2021</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">十月 2020</a><span class="archive-list-count">16</span></li></ul>
    </div>
  </div>


    
  </div>
</aside>

  
  
<aside class="sidebar sidebar-toc collapse" id="collapseToc" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    <nav id="toc" class="article-toc">
      <h3 class="toc-title">文章目录</h3>
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-embedding%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.</span> <span class="toc-text"> 1. Embedding是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-embedding%E6%8A%80%E6%9C%AF%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7"><span class="toc-number">2.</span> <span class="toc-text"> 2. Embedding技术的重要性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E5%A4%84%E7%90%86%E7%A8%80%E7%96%8F%E7%89%B9%E5%BE%81%E7%9A%84%E5%88%A9%E5%99%A8"><span class="toc-number">2.1.</span> <span class="toc-text"> （1）处理稀疏特征的利器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E5%8F%AF%E4%BB%A5%E8%9E%8D%E5%90%88%E5%A4%A7%E9%87%8F%E6%9C%89%E4%BB%B7%E5%80%BC%E4%BF%A1%E6%81%AF%E6%9C%AC%E8%BA%AB%E5%B0%B1%E6%98%AF%E6%9E%81%E5%85%B6%E9%87%8D%E8%A6%81%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F"><span class="toc-number">2.2.</span> <span class="toc-text"> （2）可以融合大量有价值信息，本身就是极其重要的特征向量</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-embedding%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%8A%80%E6%9C%AF"><span class="toc-number">3.</span> <span class="toc-text"> 3. Embedding的实现技术</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1word2vec%E9%A6%96%E6%AC%A1%E6%88%90%E5%8A%9F%E5%BA%94%E7%94%A8"><span class="toc-number">3.1.</span> <span class="toc-text"> （1）Word2Vec：首次成功应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2item2vec%E4%B8%87%E7%89%A9%E7%9A%86embedding"><span class="toc-number">3.2.</span> <span class="toc-text"> （2）Item2Vec：万物皆Embedding</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3graph-embedding"><span class="toc-number">3.3.</span> <span class="toc-text"> （3）Graph Embedding</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2deep-walk%E5%9F%BA%E4%BA%8E%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0%E7%9A%84-graph-embedding-%E6%96%B9%E6%B3%95"><span class="toc-number">3.4.</span> <span class="toc-text"> 2）Deep Walk：基于随机游走的 Graph Embedding 方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-node2vec%E5%9C%A8%E5%90%8C%E8%B4%A8%E6%80%A7%E5%92%8C%E7%BB%93%E6%9E%84%E6%80%A7%E9%97%B4%E6%9D%83%E8%A1%A1%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">3.5.</span> <span class="toc-text"> 3） Node2Vec：在同质性和结构性间权衡的方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-embedding%E7%9A%84%E5%BA%94%E7%94%A8%E6%96%B9%E6%B3%95"><span class="toc-number">4.</span> <span class="toc-text"> 4. Embedding的应用方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E7%9B%B4%E6%8E%A5%E5%BA%94%E7%94%A8"><span class="toc-number">4.1.</span> <span class="toc-text"> 1）直接应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E9%A2%84%E8%AE%AD%E7%BB%83%E5%BA%94%E7%94%A8"><span class="toc-number">4.2.</span> <span class="toc-text"> 2）预训练应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3end2end%E5%BA%94%E7%94%A8%E7%AB%AF%E5%88%B0%E7%AB%AF%E8%AE%AD%E7%BB%83"><span class="toc-number">4.3.</span> <span class="toc-text"> 3）End2End应用：端到端训练</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4%E5%B8%B8%E7%94%A8%E7%9A%84%E5%90%91%E9%87%8F%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E6%B3%95%E6%96%B9%E6%B3%95"><span class="toc-number">4.4.</span> <span class="toc-text"> 4）常用的向量相似度计算法方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E7%BB%8F%E5%85%B8%E9%97%AE%E7%AD%94"><span class="toc-number">5.</span> <span class="toc-text"> 5. 经典问答</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E6%AF%94%E8%BE%83-%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E7%AB%AF%E5%88%B0%E7%AB%AF%E8%AE%AD%E7%BB%83%E5%8C%BA%E5%88%AB"><span class="toc-number">5.1.</span> <span class="toc-text"> 1. 比较： 预训练与端到端训练区别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-deep-walk%E7%9A%84%E4%BC%98%E7%82%B9%E5%92%8C%E7%89%B9%E7%82%B9"><span class="toc-number">5.2.</span> <span class="toc-text"> 2. Deep walk的优点和特点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-autoencoder%E5%92%8Cword2vec%E7%9A%84%E5%85%B3%E7%B3%BB%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">5.3.</span> <span class="toc-text"> 3. AutoEncoder和Word2vec的关系是什么？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E6%89%A9%E5%B1%95%E9%98%85%E8%AF%BB"><span class="toc-number">6.</span> <span class="toc-text"> 6. 扩展阅读</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">7.</span> <span class="toc-text"> 参考资料</span></a></li></ol>
    </nav>
  </div>
</aside>

<main class="main" role="main">
  <div class="content">
  <article id="post-RecSys/2.特征工程/[深度学习推荐系统-笔记05]Embedding技术" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      深度学习推荐系统-笔记05：Embedding技术
    </h1>
  

      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/posts/ba149af9.html" class="article-date">
	  <time datetime="2021-01-05T13:02:30.000Z" itemprop="datePublished">2021-01-05</time>
	</a>
</span>
        
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">深度学习推荐系统</a>
  </span>

        
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/Embedding/" rel="tag">Embedding</a>
  </span>


        
	<span class="article-read hidden-xs">
	    <i class="icon icon-eye-fill" aria-hidden="true"></i>
	    <span id="busuanzi_container_page_pv">
			<span id="busuanzi_value_page_pv">0</span>
		</span>
	</span>


<!--         <span class="post-comment"><i class="icon icon-comment"></i> <a href="/posts/ba149af9.html#comments" class="article-comment-link">评论</a></span> -->
        
	
		<span class="post-wordcount hidden-xs" itemprop="wordCount">字数: 2.5k(字)</span>
	
	
		<span class="post-readcount hidden-xs" itemprop="timeRequired">预计: 9(分)</span>
	

      </div>
    </div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <h3 id="1-embedding是什么"><a class="markdownIt-Anchor" href="#1-embedding是什么"></a> 1. Embedding是什么</h3>
<p>Embedding 就是用一个数值向量“表示”一个对象（Object）的方法</p>
<img src="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221242798.png" alt="Embedding示意图" style="zoom:50%;" />
<p>解读1：左边例子，从 king 到 queen 的向量和从 man 到 woman 的向量，无论从方向还是尺度来说它们都非常接近。</p>
<p>解读2：右边例子也很典型，从 walking 到 walked 和从 swimming 到 swam 的向量基本一致，这说明词向量揭示了词之间的时态关系</p>
<h3 id="2-embedding技术的重要性"><a class="markdownIt-Anchor" href="#2-embedding技术的重要性"></a> 2. Embedding技术的重要性</h3>
<h4 id="1处理稀疏特征的利器"><a class="markdownIt-Anchor" href="#1处理稀疏特征的利器"></a> （1）处理稀疏特征的利器</h4>
<p>1）大量使用 One-hot 编码会导致样本特征向量极度稀疏</p>
<p>2）深度学习的结构特点又不利于稀疏特征向量的处理，原因如下：</p>
<p>​		① 特征过于稀疏会导致整个网络的收敛非常慢，因为每一个样本的学习只有极少数的权重会得到更新，这在样本数量有限的情况下会导致模型不收敛。</p>
<p>​		② One-hot 类稀疏特征的维度往往非常地大，可能会达到千万甚至亿的级别，如果直接连接进入深度学习网络，那整个模型的参数数量会非常庞大，这对于一般公司的算力开销来说都是吃不消的。</p>
<p>3） 因此由 Embedding 层负责将稀疏高维特征向量转换成稠密低维特征向量。</p>
<h4 id="2可以融合大量有价值信息本身就是极其重要的特征向量"><a class="markdownIt-Anchor" href="#2可以融合大量有价值信息本身就是极其重要的特征向量"></a> （2）可以融合大量有价值信息，本身就是极其重要的特征向量</h4>
<p>1）相比由原始信息直接处理得来的特征向量，Embedding 的表达能力更强</p>
<p>2）Graph Embedding 技术被提出后，Embedding 几乎可以引入任何信息进行编码，使其本身就包含大量有价值的信息</p>
<h3 id="3-embedding的实现技术"><a class="markdownIt-Anchor" href="#3-embedding的实现技术"></a> 3. Embedding的实现技术</h3>
<h4 id="1word2vec首次成功应用"><a class="markdownIt-Anchor" href="#1word2vec首次成功应用"></a> （1）Word2Vec：首次成功应用</h4>
<p>1）Word2Vec，2013年由谷歌提出。模型分为两种形式：CBOW(连续词袋模型：由相邻词预测中间词)和Skip-gram(跳词模型：由当前词预测前后相邻词)。</p>
<img src="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221254567.png" alt="Word2Vec的两种训练方式" style="zoom:50%;" />
<p>2）训练方法：</p>
<p>​	① 准备语料</p>
<p>​	② 分词，去掉停用词等无实际含义词</p>
<p>​	③ 生成词序列</p>
<p>​	④ 选取滑动窗口N，通过截取词组的方式生成训练样本</p>
<p>​	⑤ 模型训练（可以基于开源项目）</p>
<p>3）模型结构：本质是一个三层神经网络</p>
<img src="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221303479.png" alt="Word2Vec模型结构" style="zoom:50%;" />
<p>​	① 隐层激活函数：没有或者说输入即输出的恒等函数</p>
<p>​	② 输出激活函数： softmax</p>
<p>4）词向量：</p>
<img src="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221312355.png" alt="词向量训练结果" style="zoom:50%;" />
<p>​	① 输入层到隐层的权重矩阵<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mrow><mi>V</mi><mo>∗</mo><mi>N</mi></mrow></msub></mrow><annotation encoding="application/x-tex">W_{V*N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.22222em;">V</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>（输入向量矩阵） 的每一个行向量对应的就是我们要找的“词向量”。同理输出向量矩阵也可以表示，但是通常习惯使用输入向量矩阵表示“词向量”。</p>
<p>​	② 把输入向量矩阵转换成词向量查找表（Lookup table）</p>
<p>5）延伸：Word2vec还有非常多的知识点值得细细挖掘，比如：模型结构、目标函数、负采样方法、负采样中的目标函数等。建议看一下《动手学深度学习》的相关内容：<a target="_blank" rel="noopener" href="http://zh.gluon.ai/chapter_natural-language-processing/word2vec.html">10.1词嵌入</a>和<a target="_blank" rel="noopener" href="http://zh.gluon.ai/chapter_natural-language-processing/approx-training.html">10.2近似计算</a>。</p>
<h4 id="2item2vec万物皆embedding"><a class="markdownIt-Anchor" href="#2item2vec万物皆embedding"></a> （2）Item2Vec：万物皆Embedding</h4>
<p>1）Item2Vec，2015年由微软提出，它是对 Word2vec 方法的推广，使 Embedding 方法适用于几乎所有的<strong>序列数据</strong>。</p>
<img src="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221321966.png" alt="Item2Vec与Word2Vec对比" style="zoom:50%;" />
<p>2）Item2Vec 模型的技术细节几乎和 Word2vec 完全一致，只要能够用序列数据的形式把要表达的对象表示出来，再把序列数据“喂”给 Word2vec 模型，就能够得到任意物品的 Embedding了。</p>
<h4 id="3graph-embedding"><a class="markdownIt-Anchor" href="#3graph-embedding"></a> （3）Graph Embedding</h4>
<p>1）互联网的数据可不仅仅是序列数据那么简单，越来越多的数据被我们以图的形式展现出来。典型的图结构数据示意图：</p>
<img src="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221333959.png" alt="图结构数据" style="zoom:50%;" />
<p>​	① <strong>社交关系</strong>：从社交网络中，我们可以发现意见领袖，可以发现社区，再根据这些“社交”特性进行社交化的推荐。<strong>如果我们可以对社交网络中的节点进行 Embedding 编码，社交化推荐的过程将会非常方便</strong>。</p>
<p>​	② 知识图谱：知识图谱中包含了不同类型的知识主体（如人物、地点等），附着在知识主体上的属性（如人物描述，物品特点），以及主体和主体之间、主体和属性之间的关系。<strong>如果我们能够对知识图谱中的主体进行 Embedding 化，就可以发现主体之间的潜在关系，这对于基于内容和知识的推荐系统是非常有帮助的</strong>。</p>
<p>​	③ <strong>行为关系</strong>：由用户和物品组成的“二部图”，借助这样的关系图，我们自然能够<strong>利用 Embedding 技术发掘出物品和物品之间、用户和用户之间，以及用户和物品之间的关系</strong>，从而应用于推荐系统的进一步推荐。</p>
<h4 id="2deep-walk基于随机游走的-graph-embedding-方法"><a class="markdownIt-Anchor" href="#2deep-walk基于随机游走的-graph-embedding-方法"></a> 2）Deep Walk：基于随机游走的 Graph Embedding 方法</h4>
<p>​	① Deep Walk，2014年由美国石溪大学的研究者提出。</p>
<p>​	② 主要思想：由物品组成的图结构上进行随机游走，产生大量物品序列，然后将这些物品序列作为训练样本输入 Word2vec 进行训练，最终得到物品的 Embedding。</p>
<p><img src="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221342914.png" alt="图结构数据转成序列数据的方法" /></p>
<p>​	③ 跳转概率：就是遍历 vi 的邻接点 vj 的概率。</p>
<img src="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221348626.png" alt="跳转概率" style="zoom:50%;" />
<p>&lt;1&gt; 有向有权图：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mo>+</mo></msub><mo stretchy="false">(</mo><msub><mi>v</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">N_+(v_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.25833100000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>是节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>所有的出边集合，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>M</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">M_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>是节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>到节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">v_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>的边的权重，即跳转概率是跳转边的权重占所有相关出边权重之和的比例</p>
<p>&lt;2&gt; 无向无权图：是上述公式的特例，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>M</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">M_{ij}=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mo>+</mo></msub><mo stretchy="false">(</mo><msub><mi>v</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">N_+(v_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.25833100000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>是节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>所有的边集合。<!--没看懂--></p>
<h4 id="3-node2vec在同质性和结构性间权衡的方法"><a class="markdownIt-Anchor" href="#3-node2vec在同质性和结构性间权衡的方法"></a> 3） Node2Vec：在同质性和结构性间权衡的方法</h4>
<p>① Node2Vec，2016年由斯坦福大学的研究者提出。</p>
<p>② 主要思想：基于Deep Walk，Node2vec 通过调整随机游走跳转概率的方法，让 Graph Embedding 的结果在网络的**同质性（Homophily）<strong>和</strong>结构性（Structural Equivalence）**中进行权衡，可以进一步把不同的 Embedding 输入推荐模型，让推荐系统学习到不同的网络结构特点。</p>
<p><img src="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221355654.png" alt="Node2Vec结构示意图" /></p>
<p>③ 同质性：距离相近节点的 Embedding 应该尽量近似，<strong>让游走的过程更倾向于 DFS</strong>。示例：节点 u 与其相连的节点 s1、s2、s3、s4的 Embedding 表达应该是接近的。</p>
<p>④ 结构性：结构上相似的节点的 Embedding 应该尽量接近，<strong>让随机游走要更倾向于 BFS</strong>。示例：节点 u 和节点 s6都是各自局域网络的中心节点，它们在结构上相似，所以它们的 Embedding 表达也应该近似。</p>
<p>⑤ 跳转概率：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>π</mi><mrow><mi>v</mi><mi>x</mi></mrow></msub><mo>=</mo><msub><mi>α</mi><mrow><mi>p</mi><mi>q</mi></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo><mo separator="true">⋅</mo><msub><mi>w</mi><mrow><mi>v</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\pi_{vx}=\alpha_{pq}(t,x)·w_{vx}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<img src="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221404937.png" alt="跳转概率" style="zoom:50%;" />
<p>&lt;1&gt; <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>v</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{vx}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>v</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">vx</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mord mathdefault">x</span></span></span></span>的原始权重，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>α</mi><mrow><mi>p</mi><mi>q</mi></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\alpha_{pq}(t,x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>如上图所示，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mrow><mi>t</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{tx}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathdefault">t</span></span></span></span>和距离节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>(节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span></span></span></span>的下一个节点)的距离。</p>
<p>&lt;2&gt; 参数 p 被称为返回参数（Return Parameter），p 越小，随机游走回节点 t 的可能性越大，Node2vec 就更注重表达网络的结构性</p>
<p>&lt;3&gt; 参数 q 被称为进出参数（In-out Parameter），q 越小，随机游走到远方节点的可能性越大，Node2vec 更注重表达网络的同质性。</p>
<p>&lt;4&gt; <strong>计算出的概率需要做归一化，使节点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span></span></span></span>到所有下一个节点的概率和为1。</strong></p>
<h3 id="4-embedding的应用方法"><a class="markdownIt-Anchor" href="#4-embedding的应用方法"></a> 4. Embedding的应用方法</h3>
<h4 id="1直接应用"><a class="markdownIt-Anchor" href="#1直接应用"></a> 1）直接应用</h4>
<p>① 利用物品 Embedding 间的相似性实现相似物品推荐</p>
<p>② 利用物品 Embedding 和用户 Embedding 的相似性实现“猜你喜欢”等经典推荐功能</p>
<p>③ 利用物品 Embedding 实现推荐系统中的召回层</p>
<h4 id="2预训练应用"><a class="markdownIt-Anchor" href="#2预训练应用"></a> 2）预训练应用</h4>
<p>把这些 Embedding 向量作为特征向量的一部分，跟其余的特征向量拼接起来，作为推荐模型的输入参与训练</p>
<h4 id="3end2end应用端到端训练"><a class="markdownIt-Anchor" href="#3end2end应用端到端训练"></a> 3）End2End应用：端到端训练</h4>
<p>① 概念：不预先训练 Embedding，而是把 Embedding 的训练与深度学习推荐模型结合起来，采用统一的、端到端的方式一起训练，直接得到包含 Embedding 层的推荐模型</p>
<p>② 案例：微软的<code>Deep Crossing</code>，UCL 提出的 <code>FNN</code> 和 Google 的 <code>Wide&amp;Deep</code></p>
<img src="https://gitee.com/acdance/img/raw/master/blogs/image-20210128221412660.png" alt="端到端训练" style="zoom:59%;" />
<h4 id="4常用的向量相似度计算法方法"><a class="markdownIt-Anchor" href="#4常用的向量相似度计算法方法"></a> 4）常用的向量相似度计算法方法</h4>
<p>请参考<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1668762">《计算向量间相似度的常用方法》</a>。</p>
<h3 id="5-经典问答"><a class="markdownIt-Anchor" href="#5-经典问答"></a> 5. 经典问答</h3>
<h4 id="1-比较-预训练与端到端训练区别"><a class="markdownIt-Anchor" href="#1-比较-预训练与端到端训练区别"></a> 1. 比较： 预训练与端到端训练区别</h4>
<p>Embedding预训练的优点：</p>
<p>① 更快。因为对于End2End的方式，Embedding层的优化还受推荐算法的影响，这会增加计算量。</p>
<p>② 难收敛。推荐算法是以Embedding为前提的，在端到端的方式中，训练初期由于Embedding层的结果没有意义，所以推荐模块的优化也可能不太有意义，可能无法有效收敛。</p>
<p>Embedding端到端的优点：</p>
<p>① 能够找到Embedding层在这个模型结构下的最优解。因为端到端将Embedding训练和推荐算法连接起来训练，那么Embedding层可以学习到最有利于推荐目标的Embedding结果。</p>
<h4 id="2-deep-walk的优点和特点"><a class="markdownIt-Anchor" href="#2-deep-walk的优点和特点"></a> 2. Deep walk的优点和特点</h4>
<p>① 去掉多余噪音信息，关注主要矛盾，所以一般要生成比原样本更少的样本量</p>
<p>② deep walk的抽样过程保留了转移矩阵的“主要框架”，但同时当抽样次数不太高的时候，item embedding的覆盖率反而没有item2vec好</p>
<h4 id="3-autoencoder和word2vec的关系是什么"><a class="markdownIt-Anchor" href="#3-autoencoder和word2vec的关系是什么"></a> 3. AutoEncoder和Word2vec的关系是什么？</h4>
<p>没找到特别好的材料，欢迎留言，参考 <a target="_blank" rel="noopener" href="https://spaces.ac.cn/archives/4233">SVD分解(三)：连Word2Vec都只不过是个SVD？</a>中的说法：</p>
<blockquote>
<p>结构上：Word2vec与AutoEncoder和SVD是一样的；</p>
<p>实现上：Word2Vec最后接的是softmax来预测概率，也就是说实现了一个非线性变换，而自编码器或者SVD并没有。</p>
</blockquote>
<h3 id="6-扩展阅读"><a class="markdownIt-Anchor" href="#6-扩展阅读"></a> 6. 扩展阅读</h3>
<p>强烈建议大家阅读下王喆推荐的<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/58805184">Embedding从入门到专家必读的十篇论文</a>。</p>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<p>《深度学习推荐系统实战》 – 极客时间，王喆</p>
<blockquote>
<p>本文首发于个人小站：<a target="_blank" rel="noopener" href="https://notlate.net/posts/ba149af9.html">NotLate.net</a>，欢迎关注。</p>
</blockquote>

      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="https://www.notlate.net/posts/ba149af9.html" title="深度学习推荐系统-笔记05：Embedding技术" target="_blank" rel="external">https://www.notlate.net/posts/ba149af9.html</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote>


<!-- <div class="panel panel-default panel-badger"> -->
<!--   <div class="panel-body"> -->
<!--     <figure class="media"> -->
<!--       <div class="media-left"> -->
<!--         <a href="" target="_blank" class="img-burn thumb-sm visible-lg"> -->
<!--           <img src="/images/logo.png" class="img-rounded w-full" alt=""> -->
<!--         </a> -->
<!--       </div> -->
<!--       <div class="media-body"> -->
<!--         <h3 class="media-heading"><a href="" target="_blank"><span class="text-dark">ACDance</span><small class="ml-1x">一无所知，或是没被理解；&lt;br/&gt;一事无成，或是没被重视。</small></a></h3> -->
<!--         <div></div> -->
<!--       </div> -->
<!--     </figure> -->
<!--   </div> -->
<!-- </div> -->


    </div>
  </article>
  
  
    
  <section id="comments">
  	
      <div id="vcomments"></div>
    
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/posts/9eb245b5.html" title="深度学习推荐系统-笔记06：推荐系统线上服务相关"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
    </li>
    
    
    <li class="next">
      <a href="/posts/75f170bd.html" title="深度学习推荐系统-笔记04：特征工程介绍"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
    <li class="toggle-toc">
      <a class="toggle-btn collapsed" data-toggle="collapse" href="#collapseToc" aria-expanded="false" title="文章目录" role="button">
        <span>[&nbsp;</span><span>文章目录</span>
        <i class="text-collapsed icon icon-anchor"></i>
        <i class="text-in icon icon-close"></i>
        <span>]</span>
      </a>
    </li>
    
  </ul>
  
  
  <!-- Button trigger modal -->
  <button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>赏</span></button>
  <!-- <div class="wave-icon wave-icon-danger btn-donate" data-toggle="modal" data-target="#donateModal">
    <div class="wave-circle"><span class="icon"><i class="icon icon-bill"></i></span></div>
  </div> -->
  
  
  <div class="bar-right">
    
  </div>
  </div>
</nav>
  
<!-- Modal -->
<div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog">
  <div class="modal-dialog" role="document">
    <div class="modal-content donate">
      <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
      <div class="modal-body">
        <div class="donate-box">
          <div class="donate-head">
            <p>感谢您的支持，我会继续努力的!</p>
          </div>
          <div class="tab-content">
            <div role="tabpanel" class="tab-pane fade active in" id="alipay">
              <div class="donate-payimg">
                <img src="/images/donate/alipayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开支付宝扫一扫，即可进行扫码打赏哦</p>
            </div>
            <div role="tabpanel" class="tab-pane fade" id="wechatpay">
              <div class="donate-payimg">
                <img src="/images/donate/wechatpayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开微信扫一扫，即可进行扫码打赏哦</p>
            </div>
          </div>
          <div class="donate-footer">
            <ul class="nav nav-tabs nav-justified" role="tablist">
              <li role="presentation" class="active">
                <a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> 支付宝</a>
              </li>
              <li role="presentation" class="">
                <a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> 微信支付</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>



</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/NotLateYet" target="_blank" title="Github" ><i class="icon icon-github"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" ><i class="icon icon-rss"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        &copy; 2021 ACDance
        
<!--         <div class="publishby"> -->
<!--         	Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>. -->
<!--         </div> -->
    </div>
</footer>
  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>






   
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





   
    
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/valine"></script>
  <script type="text/javascript">
  var GUEST = ['nick', 'mail', 'link'];
  var meta = 'nick,mail,link';
  meta = meta.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#vcomments',
    verify: true,
    notify: false,
    appId: 'rjHvwlAnqIFCN31UINTnwMEL-gzGzoHsz',
    appKey: '2Q9D5J3pYGojfU6ppehPEnB3',
    placeholder: '欢迎提出意见和建议',
    avatar: 'mm',
    meta: meta,
    pageSize: '10' || 10,
    visitor: false
  });
  </script>

     



  <script src="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.3.5/dist/jquery.fancybox.min.js"></script>
  <script>
  //利用 FancyBox 实现点击图片放大
  $(document).ready(function() {
    $('article img').not('[hidden]').not('.panel-body img').each(function() {
      var $image = $(this);
      var imageCaption = $image.attr('alt');
      var $imageWrapLink = $image.parent('a');
      if ($imageWrapLink.length < 1) {
        var src = this.getAttribute('src');
        var idx = src.lastIndexOf('?');
        if (idx != -1) {
          src = src.substring(0, idx);
        }
        $imageWrapLink = $image.wrap('<a href="' + src + '"></a>').parent('a');
      }
      $imageWrapLink.attr('data-fancybox', 'images');
      if (imageCaption) {
        $imageWrapLink.attr('data-caption', imageCaption);
      }
    });
    $().fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
    });
  });
  </script>




    <script defer>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?8efc12c51b549f06ae0c6a3c0d0f2e56";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>